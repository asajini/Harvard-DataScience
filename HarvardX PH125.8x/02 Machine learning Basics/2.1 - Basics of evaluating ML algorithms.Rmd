---
title: "2.1 - Basics of Evaluating Machine Learning Algorithms"
author: "Sajini Arumugam"
date: "6/29/2020"
output: html_document
weight: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<font size = "4">
## **Caret package, training and test sets, and overall accuracy**  

### ***Basics of Evaluating Machine Learning Algorithms***  

#### **Question 1**  
  For each of the following, indicate whether the         outcome is continuous or categorical.<br/>

  Digit Reader - Categorical  
  Height - Continuous  
  Spam Filter - Categorical  
  Stock Prices - Continuous  
  Sex - Categorical  


#### **Question 2**  
  How many features are available to us for prediction    in the mnist digits dataset?<br/>
  
  ```
  mnist <- read_mnist()
  ncol(mnist$train$images)
  ```

## **CONFUSION MATRIX **

### *Comprehension Check: Practice with Machine Learning, Part 1*

The following questions all ask you to work with the dataset described below.

The reported_heights and heights datasets were collected from three classes taught in the Departments of Computer Science and Biostatistics, as well as remotely through the Extension School. The Biostatistics class was taught in 2016 along with an online version offered by the Extension School. On 2016-01-25 at 8:15 AM, during one of the lectures, the instructors asked student to fill in the sex and height questionnaire that populated the reported_heights dataset. The online students filled out the survey during the next few days, after the lecture was posted online. We can use this insight to define a variable which we will call type, to denote the type of student, inclass or online.

The code below sets up the dataset for you to analyze in the following exercises:

```{r}
library(dslabs)
library(dplyr)
library(lubridate)
data(reported_heights)

dat <- mutate(reported_heights, date_time = ymd_hms(time_stamp)) %>%
  filter(date_time >= make_date(2016, 01, 25) & date_time < make_date(2016, 02, 1)) %>%
  mutate(type = ifelse(day(date_time) == 25 & hour(date_time) == 8 & between(minute(date_time), 15, 30), "inclass","online")) %>%
  select(sex, type)

y <- factor(dat$sex, c("Female", "Male"))
x <- dat$type
```

#### **Question 1**

The type column of dat indicates whether students took classes in person ("inclass") or online ("online"). What proportion of the inclass group is female? What proportion of the online group is female?

Enter your answer as a percentage or decimal (eg "50%" or "0.50") to at least the hundredths place.

```{r}
dat %>% group_by(type) %>% summarize(prop_female = mean(sex == "Female"))
```

#### **Question 2**  

In the course videos, height cutoffs were used to predict sex. Instead of using height, use the type variable to predict sex. Use what you learned in Q1 to make an informed guess about sex based on the most prevalent sex for each type. Report the accuracy of your prediction of sex. You do not need to split the data into training and test sets.

Enter your accuracy as a percentage or decimal (eg "50%" or "0.50") to at least the hundredths place.

```{r}
y_hat <- ifelse(x == "online", "Male", "Female") %>% 
      factor(levels = levels(y))
mean(y_hat==y)
```


#### **Question 3**

Write a line of code using the table() function to show the confusion matrix between y_hat and y. Use the exact format function(a, b) (note the spacing!) for your answer and do not name the columns and rows.

Type the line of code below:

```{r}
table(y_hat, y)
```


#### **Question 4**  
What is the sensitivity of this prediction? You can use the sensitivity() function from the caret package. Enter your answer as a percentage or decimal (eg "50%" or "0.50") to at least the hundredths place.

```{r}
library(caret)
sensitivity(y_hat, y)
```


#### **Question 5**  
What is the specificity of this prediction? You can use the specificity() function from the caret package. Enter your answer as a percentage or decimal (eg "50%" or "0.50") to at least the hundredths place.


```{r}
library(caret)
specificity(y_hat, y)
```


#### **Question 6**  
What is the prevalence (% of females) in the dat dataset defined above? Enter your answer as a percentage or decimal (eg "50%" or "0.50") to at least the hundredths place.

```{r}
mean(y == "Female")
```
***

### **Comprehension Check: Practice with Machine Learning, Part 2**  

We will practice building a machine learning algorithm using a new dataset, iris, that provides multiple predictors for us to use to train. To start, we will remove the setosa species and we will focus on the versicolor and virginica iris species using the following code:

```{r}
library(caret)
data(iris)
iris <- iris[-which(iris$Species=='setosa'),]
y <- iris$Species
```


#### **Question 7**  
First let us create an even split of the data into train and test partitions using createDataPartition() from the caret package. The code with a missing line is given below:

```{r}
test_index <- createDataPartition(y,times=1,p=0.5,list=FALSE)
test <- iris[test_index,]
train <- iris[-test_index,]
```

Which code should be used in place of # line of code above?
```
test_index <- createDataPartition(y,times=1,p=0.5,list=FALSE)
```

#### **Question 8**  
Next we will figure out the singular feature in the dataset that yields the greatest overall accuracy when predicting species. You can use the code from the introduction and from Q7 to start your analysis.

Using only the train iris dataset, for each feature, perform a simple search to find the cutoff that produces the highest accuracy, predicting virginica if greater than the cutoff and versicolor otherwise. Use the seq function over the range of each feature by intervals of 0.1 for this search.

Which feature produces the highest accuracy?

- Sepal.Length
- Sepal.Width
- Petal.Length *
- Petal.Width

**Question 9**  
For the feature selected in Q8, use the smart cutoff value from the training data to calculate overall accuracy in the test data. What is the overall accuracy?

```
library(dplyr)

predictions <- foo(train[,3])
rangedValues <- seq(range(train[,3])[1],range(train[,3])[2],by=0.1)
cutoffs <-rangedValues[which(predictions==max(predictions))]

y_hat <- ifelse(test[,3]>cutoffs[1],'virginica','versicolor')
mean(y_hat==test$Species)
```

#### **Question 10**  
Notice that we had an overall accuracy greater than 96% in the training data, but the overall accuracy was lower in the test data. This can happen often if we overtrain. In fact, it could be the case that a single feature is not the best choice. For example, a combination of features might be optimal. Using a single feature and optimizing the cutoff as we did on our training data can lead to overfitting.

Given that we know the test data, we can treat it like we did our training data to see if the same feature with a different cutoff will optimize our predictions. Redo the analysis from Q8, this time using the test set.

Which feature best optimizes our overall accuracy?

- Sepal.Length
- Sepal.Width
- Petal.Length
- Petal.Width  *

```{r}
foo <- function(x){
	rangedValues <- seq(range(x)[1],range(x)[2],by=0.1)
	sapply(rangedValues,function(i){
		y_hat <- ifelse(x>i,'virginica','versicolor')
		mean(y_hat==test$Species)
	})
}
predictions <- apply(test[,-5],2,foo)
sapply(predictions,max)	
```


#### **Question 11**  
Now we will perform some exploratory data analysis on the data.
```{r}
plot(iris,pch=21,bg=iris$Species)
```

Notice that Petal.Length and Petal.Width in combination could potentially be more information than either feature alone.

Optimize the the cutoffs for Petal.Length and Petal.Width separately in the train dataset by using the seq function with increments of 0.1. Then, report the overall accuracy when applied to the test dataset by creating a rule that predicts virginica if Petal.Length is greater than the length cutoff OR Petal.Width is greater than the width cutoff, and versicolor otherwise.

What is the overall accuracy for the test data now?

```{r}
library(caret)
data(iris)
iris <- iris[-which(iris$Species=='setosa'),]
y <- iris$Species

plot(iris,pch=21,bg=iris$Species)

set.seed(2)
test_index <- createDataPartition(y,times=1,p=0.5,list=FALSE)
test <- iris[test_index,]
train <- iris[-test_index,]
            
petalLengthRange <- seq(range(train$Petal.Length)[1],range(train$Petal.Length)[2],by=0.1)
petalWidthRange <- seq(range(train$Petal.Width)[1],range(train$Petal.Width)[2],by=0.1)

length_predictions <- sapply(petalLengthRange,function(i){
		y_hat <- ifelse(train$Petal.Length>i,'virginica','versicolor')
		mean(y_hat==train$Species)
	})
length_cutoff <- petalLengthRange[which.max(length_predictions)] # 4.7

width_predictions <- sapply(petalWidthRange,function(i){
		y_hat <- ifelse(train$Petal.Width>i,'virginica','versicolor')
		mean(y_hat==train$Species)
	})
width_cutoff <- petalWidthRange[which.max(width_predictions)] # 1.5

y_hat <- ifelse(test$Petal.Length>length_cutoff | test$Petal.Width>width_cutoff,'virginica','versicolor')
mean(y_hat==test$Species)
```

