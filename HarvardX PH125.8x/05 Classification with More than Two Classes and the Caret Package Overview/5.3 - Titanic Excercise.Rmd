---
title: "5.3 - Titanic Exercise"
author: "Sajini Arumugam"
output: html_document
weight: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
<br/>

## Titanic Exercises Part 1

These exercises cover everything you have learned in this course so far. You will use the background information to provided to train a number of different types of models on this dataset.

### Background

The Titanic was a British ocean liner that struck an iceberg and sunk on its maiden voyage in 1912 from the United Kingdom to New York. More than 1,500 of the estimated 2,224 passengers and crew died in the accident, making this one of the largest maritime disasters ever outside of war. The ship carried a wide range of passengers of all ages and both genders, from luxury travelers in first-class to immigrants in the lower classes. However, not all passengers were equally likely to survive the accident. You will use real data about a selection of 891 passengers to predict which passengers survived.

### Libraries and data

Use the titanic_train data frame from the titanic library as the starting point for this project.

```{r}
library(titanic)    # loads titanic_train data frame
library(caret)
library(tidyverse)
library(rpart)
library(dplyr)
library(rpart.plot)
# 3 significant digits
options(digits = 3)

# clean the data - `titanic_train` is loaded with the titanic package
titanic_clean <- titanic_train %>%
    mutate(Survived = factor(Survived),
           Embarked = factor(Embarked),
           Age = ifelse(is.na(Age), median(Age, na.rm = TRUE), Age), # NA age to median age
           FamilySize = SibSp + Parch + 1) %>%    # count family members
    select(Survived,  Sex, Pclass, Age, Fare, SibSp, Parch, FamilySize, Embarked)
```
<br/>

#### **Question 1: Training and test sets**  
Split titanic_clean into test and training sets - after running the setup code, it should have 891 rows and 9 variables.

Set the seed to 42, then use the caret package to create a 20% data partition based on the Survived column. Assign the 20% partition to test_set and the remaining 80% partition to train_set.

```{r}
set.seed(42, sample.kind = "Rounding")
test_index <- createDataPartition(titanic_clean$Survived, times= 1, p = 0.2, list = FALSE)
test_set <- titanic_clean %>% slice(test_index)
train_set <- titanic_clean %>% slice(-test_index)

nrow(test_set)
nrow(train_set)
mean(train_set$Survived == 1)
```
<br/>

#### **Question 2: Baseline prediction by guessing the outcome**  
The simplest prediction method is randomly guessing the outcome without using additional predictors. These methods will help us determine whether our machine learning algorithm performs better than chance. How accurate are two methods of guessing Titanic passenger survival?

Set the seed to 3. For each individual in the test set, randomly guess whether that person survived or not by sampling from the vector c(0,1) (Note: use the default argument setting of prob from the sample function). Assume that each person has an equal chance of surviving or not surviving.

What is the accuracy of this guessing method?

```{r}
set.seed(3, sample.kind = "Rounding")
y_hat <- sample(c(0,1), length(test_set$Survived), replace = TRUE, prob = NULL)
mean(y_hat == test_set$Survived)
```
<br/>

#### **Question 3a: Predicting survival by sex**
Use the training set to determine whether members of a given sex were more likely to survive or die. Apply this insight to generate survival predictions on the test set.

What proportion of training set females & males survived?

```{r}
train_set %>%
  group_by(Sex) %>%
  summarize(Survived = mean(Survived == 1))
```
<br/>

#### **Question 3b: Predicting survival by sex**  
Predict survival using sex on the test set: if the survival rate for a sex is over 0.5, predict survival for all individuals of that sex, and predict death if the survival rate for a sex is under 0.5.

What is the accuracy of this sex-based prediction method on the test set?

##### *method 1* 

```{r}
test_set %>%
  summarize( (sum(Sex == 'female' & Survived == 1) + sum(Sex == 'male' & Survived == 0)) / n())
```

##### *method 2*  

```{r}
sex_model <- ifelse(test_set$Sex =="female", 1, 0)
  mean(sex_model == test_set$Survived) 
```
<br/>


#### **Question 4a: Predicting survival by passenger class**  
In the training set, which class(es) (Pclass) of passengers were more likely to survive than die?

```{r}
train_set %>%
    group_by(Pclass) %>%
    summarize(Survived = mean(Survived == 1))
```
<br/>

#### **Question 4b: Predicting survival by passenger class**  
Predict survival using passenger class on the test set: predict survival if the survival rate for a class is over 0.5, otherwise predict death.

What is the accuracy of this class-based prediction method on the test set?

```{r}
 class_model <- ifelse(test_set$Pclass == 1, 1, 0)
  mean(class_model == test_set$Survived)
```
<br/>

#### **Question 4c: Predicting survival by passenger class**  

```{r}
train_set %>%
    group_by(Pclass, Sex) %>%
    summarize(Survived = mean(Survived == 1))
```
<br/>

#### **Question 4d: Predicting survival by passenger class**  

```{r}
class_sex_model <- ifelse(test_set$Sex == "female" & test_set$Pclass %in% c(1,2), 1, 0)
  mean(class_sex_model == test_set$Survived)
```
<br/>

#### **Question 5: Confusion matrix**  
Use the confusionMatrix() function to create confusion matrices for the sex model, class model, and combined sex and class model. You will need to convert predictions and survival status to factors to use this function.

What is the "positive" class used to calculate confusion matrix metrics?
Which model has the highest sensitivity?
Which model has the highest specificity?
Which model has the highest balanced accuracy?

```{r}
 confusionMatrix(data = factor(sex_model), reference = test_set$Survived)
  confusionMatrix(data = factor(class_model), reference = test_set$Survived)
  confusionMatrix(data = factor(class_sex_model), reference = test_set$Survived)
```
<br/>

#### **Question 6: F1 scores** 
Use the F_meas() function to calculate  F1  scores for the sex model, class model, and combined sex and class model. You will need to convert predictions to factors to use this function.

Which model has the highest  F1  score?

```{r}
F_meas(data = factor(sex_model), reference = test_set$Survived)
  F_meas(data = factor(class_model), reference = test_set$Survived)
  F_meas(data = factor(class_sex_model), reference = test_set$Survived)
```
<br/>

#### **Question 7: Survival by fare - LDA and QDA**  
Set the seed to 1. Train a model using linear discriminant analysis (LDA) with the caret lda method using fare as the only predictor.

What is the accuracy on the test set for the LDA model?

```{r, warning=FALSE}
set.seed(1, sample.kind = "Rounding")
  lda_model <- train(Survived~Fare, model = "lda", data = train_set)
  lda_predict <- predict(lda_model, test_set)
  mean(lda_predict == test_set$Survived)
```

Set the seed to 1. Train a model using quadratic discriminant analysis (QDA) with the caret qda method using fare as the only predictor.

What is the accuracy on the test set for the QDA model?

```{r, warning=FALSE}
 qda_model <- train(Survived~Fare, model = "qda", data = train_set)
  qda_predict <- predict(qda_model, test_set)
  mean(qda_predict == test_set$Survived)
```
<br/>

#### **Question 8: Logistic regression models**  
Set the seed to 1. Train a logistic regression model using caret train() with the glm method using age as the only predictor.

What is the accuracy on the test set using age as the only predictor?

```{r}
set.seed(1, sample.kind = "Rounding")
  glm_model <- train(Survived~Age, method = "glm", data = train_set)
  glm_predict <- predict(glm_model, test_set)
  mean(glm_predict == test_set$Survived)
```

Set the seed to 1. Train a logistic regression model using caret train() with the glm method using four predictors: sex, class, fare, and age.

What is the accuracy on the test set using these four predictors?

```{r}
glm1_model <- train(Survived~Sex+Pclass+Fare+Age, method = "glm", data = train_set)
  glm1_predict <- predict(glm1_model, test_set)
  mean(glm1_predict == test_set$Survived)
```

Set the seed to 1. Train a logistic regression model using caret train() with the glm method using all predictors. Ignore warnings about rank-deficient fit.

What is the accuracy on the test set using all predictors?
```{r, warning=FALSE}
glm2_model <- train(Survived~., method = "glm", data = train_set)
  glm2_predict <- predict(glm2_model, test_set)
  mean(glm2_predict == test_set$Survived)
```
<br/>

#### **Question 9a: kNN model**  
Set the seed to 6. Train a kNN model on the training set using the caret train function. Try tuning with k = seq(3, 51, 2).

What is the optimal value of the number of neighbors k?

```{r}
set.seed(6, sample.kind = "Rounding")
  knn_model <- train(Survived~., method = "knn",
                     data = train_set,
                     tuneGrid = data.frame(k = seq(3,51,2)))
  knn_model$bestTune
```
<br/>

#### **Question 9b: kNN model**  
Plot the kNN model to investigate the relationship between the number of neighbors and accuracy on the training set.

Of these values of  k , which yields the highest accuracy?

```{r}
 ggplot(knn_model)
```
<br/>

#### **Question 9c: kNN model**  
What is the accuracy of the kNN model on the test set?

```{r}
 knn_predict <- predict(knn_model, test_set)
  mean(knn_predict == test_set$Survived)
```
<br/>

#### **Question 10: Cross-validation**  
Set the seed to 8 and train a new kNN model. Instead of the default training control, use 10-fold cross-validation where each partition consists of 10% of the total.

Try tuning with k = seq(3, 51, 2). What is the optimal value of k using cross-validation?
What is the accuracy on the test set using the cross-validated kNN model?


```{r}
set.seed(8, sample.kind = "Rounding")
 cross_val <- trainControl(method = "cv", n = 10, p = 0.9)
 knn_cross_model <- train(Survived ~ ., method = "knn",
                          data = train_set,
                          tuneGrid = data.frame(k = seq(3,51,2)),
                          trControl = cross_val)
 knn_cross_model$bestTune
 
 knn_cross_predict <- predict(knn_cross_model, test_set)
 mean(knn_cross_predict == test_set$Survived)
```
<br/>

#### **Question 11a: Classification tree model**  
Set the seed to 10. Use caret to train a decision tree with the rpart method. Tune the complexity parameter with cp = seq(0, 0.05, 0.002).

What is the optimal value of the complexity parameter (cp)?

```{r}
set.seed(10, sample.kind = "Rounding")
 rpart_model <- train(Survived ~ ., method = "rpart", 
              data = train_set,
              tuneGrid = data.frame(cp = seq(0, 0.05, 0.002)))
 ggplot(rpart_model)
 rpart_model$bestTune
  rpart_predict <- predict(rpart_model, test_set)
 mean(rpart_predict == test_set$Survived)
 confusionMatrix(rpart_model)
```

#### **Question 11b: Classification tree model**  
Inspect the final model and plot the decision tree.

Which variables are used in the decision tree?

```{r}
 prp(rpart_model$finalModel)
```

#### **Question 11c: Classification tree model**  
Using the decision rules generated by the final model, predict whether the following individuals would survive.

```{r}
library(rattle)
 library(rpart.plot)
 library(RColorBrewer)
 fancyRpartPlot(rpart_model$finalModel, cex = 0.7)
 
 # which(test_set$Sex =="male" & test_set$SibSp == 4)
 # predict(rpart_model, test_set)
 
 # storing in a seperate data set to make things easier
 
 # 28 year old male
 male_28 <- test_set %>% filter(Sex == "male" & Age == 28)
 predict(rpart_model, male_28)
 
 #A female in the second passenger class
 female_2pclass <- test_set %>% filter(Sex == "female" & Pclass == 2)
 predict(rpart_model, female_2pclass)
 
 #A third-class female who paid a fare of $8
 female_3_class <- test_set %>% filter(Sex == "female" & Pclass == 3 & Fare <=8)
 #female_3_class
 which(test_set$Sex =="female" & test_set$Pclass == 3)
 predict(rpart_model, female_3_class)
 
 #A 5-year-old male with 4 siblings
 
 male_5yr <- test_set %>% filter(Sex == "male"  & Age == 5 & SibSp == 4)
 male_5yr
 predict(rpart_model, male_5yr)
 
 #A first-class 17-year-old female with 2 siblings
 which(test_set$Sex =="female" & test_set$Pclass == 1 & test_set$SibSp == 2)
 predict(rpart_model, test_set[145,])
 
 female_17 <- test_set %>% filter(Sex == "female" & Pclass == 1 & SibSp == 2)
 female_17
 predict(rpart_model, female_17)
 
 #first class 17 yr old male with 2 siblings
 
 male_17 <- test_set %>% filter(Sex == "male" & Pclass == 1)
 male_17
```
<br/>

#### **Question 12: Random forest model**  
Set the seed to 14. Use the caret train() function with the rf method to train a random forest. Test values of mtry ranging from 1 to 7. Set ntree to 100.

What mtry value maximizes accuracy?
What is the accuracy of the random forest model on the test set?

```{r}
set.seed(14, sample.kind = "Rounding")
 rf_model <- train(Survived~., method = "rf", ntree = 100,
                   data = train_set,
                    tuneGrid = data.frame(mtry = seq(1,7)))
 rf_model$bestTune
 
 rf_predict <- predict(rf_model, test_set)
 mean(rf_predict == test_set$Survived) 
 
 varImp(rf_model)
```

